{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc8b65a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# ===================================================================\n",
    "# CELL 1: Install Dependencies\n",
    "# ===================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# Check if running in Colab\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth\n",
    "else:\n",
    "    # Colab-specific installation\n",
    "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
    "    !pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
    "    !pip install --no-deps unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28462f38",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# Install additional dependencies\n",
    "!pip install openai fastapi uvicorn nest-asyncio pyngrok pydantic python-multipart\n",
    "!pip install ffmpeg-python pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14953643",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# ===================================================================\n",
    "# CELL 2: Import Libraries\n",
    "# ===================================================================\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from unsloth import FastLanguageModel\n",
    "import openai\n",
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "import uvicorn\n",
    "from pyngrok import ngrok\n",
    "import nest_asyncio\n",
    "import tempfile\n",
    "import os\n",
    "from typing import Optional\n",
    "import json\n",
    "\n",
    "# Apply nest_asyncio to allow running FastAPI in Colab\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a60bd4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"enter you key\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8877c360",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# ===================================================================\n",
    "# CELL 4: Load Fine-Tuned Model\n",
    "# ===================================================================\n",
    "print(\"Loading fine-tuned model...\")\n",
    "\n",
    "# Path to your fine-tuned model\n",
    "model_path = \"abdulsamad99/My_updated_Medical_Note_Generation-fine-tuning\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Load model\n",
    "model, _ = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_path,\n",
    "    load_in_4bit=True,\n",
    "    dtype=torch.float16,\n",
    ")\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "print(\"✓ Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e427d6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# ===================================================================\n",
    "# CELL 5: Audio Transcription Function\n",
    "# ===================================================================\n",
    "def transcribe_audio(audio_file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Transcribe audio file using OpenAI Whisper API\n",
    "    \n",
    "    Args:\n",
    "        audio_file_path: Path to audio file\n",
    "        \n",
    "    Returns:\n",
    "        Transcribed text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(audio_file_path, \"rb\") as audio_file:\n",
    "            transcript = openai.audio.transcriptions.create(\n",
    "                model=\"whisper-1\",\n",
    "                file=audio_file,\n",
    "                response_format=\"text\"\n",
    "            )\n",
    "        return transcript\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Transcription failed: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec78a04f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# ===================================================================\n",
    "# CELL 6: Dialogue Segmentation Function\n",
    "# ===================================================================\n",
    "def segment_dialogue(transcribed_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Segment raw transcription into doctor-patient dialogue turns\n",
    "    Uses GPT-4 to intelligently parse and format the conversation\n",
    "    \n",
    "    Args:\n",
    "        transcribed_text: Raw transcription text\n",
    "        \n",
    "    Returns:\n",
    "        Formatted dialogue with Doctor/Patient labels\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"\"\"You are a medical transcription assistant. Your task is to segment a raw doctor-patient conversation transcript into structured dialogue turns.\n",
    "\n",
    "Format each turn as:\n",
    "Doctor: [what the doctor said]\n",
    "Patient: [what the patient said]\n",
    "\n",
    "Rules:\n",
    "- Identify speaker changes based on context and conversational flow\n",
    "- Maintain chronological order\n",
    "- Do not add, remove, or modify the actual content\n",
    "- Only format and label speakers\n",
    "- If speaker is unclear, make best judgment based on medical context\"\"\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Segment this medical conversation:\\n\\n{transcribed_text}\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Dialogue segmentation failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2968aa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# ===================================================================\n",
    "# CELL 7: Clinical Note Generation Function\n",
    "# ===================================================================\n",
    "def generate_clinical_note(dialogue: str, max_new_tokens=350) -> str:\n",
    "    \"\"\"\n",
    "    Generate clinical note from dialogue using fine-tuned model\n",
    "    \n",
    "    Args:\n",
    "        dialogue: Formatted doctor-patient dialogue\n",
    "        max_new_tokens: Maximum tokens to generate\n",
    "        \n",
    "    Returns:\n",
    "        Generated clinical note\n",
    "    \"\"\"\n",
    "    # Full section list\n",
    "    header_list = (\n",
    "        \"fam/sochx, genhx, pastmedicalhx, cc, pastsurgical, allergy, ros, medications, \"\n",
    "        \"assessment, exam, diagnosis, disposition, plan, edcourse, immunizations, \"\n",
    "        \"imaging, gynhx, procedures, other_history, labs\"\n",
    "    )\n",
    "    \n",
    "    # SYSTEM\n",
    "    system_message = (\n",
    "        \"You are a medical scribe AI assistant. Your task is to read a doctor–patient \"\n",
    "        \"dialogue and generate a clinical note for the correct documentation section. \"\n",
    "        \"Use ONLY the dialogue. Never hallucinate.\"\n",
    "    )\n",
    "    \n",
    "    # USER\n",
    "    user_message = f\"\"\"Choose exactly ONE section from this list:\n",
    "{header_list}\n",
    "\n",
    "Rules:\n",
    "- Use ONLY information stated in the dialogue.\n",
    "- Be concise and medically accurate.\n",
    "- Do not infer or add assumptions.\n",
    "\n",
    "Format:\n",
    "<section_header>\n",
    "<section_text>\n",
    "\n",
    "Dialogue:\n",
    "{dialogue}\"\"\"\n",
    "    \n",
    "    # Build prompt EXACTLY like training format\n",
    "    prompt = (\n",
    "        f\"<|im_start|>system<|im_sep|>{system_message}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>user<|im_sep|>{user_message}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>assistant<|im_sep|>\"\n",
    "    )\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        inputs = inputs.to(\"cuda\")\n",
    "    \n",
    "    # Generate\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.3,\n",
    "            top_p=0.9,\n",
    "            do_sample=False,\n",
    "            eos_token_id=tokenizer.convert_tokens_to_ids(\"<|im_end|>\"),\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # Decode full output\n",
    "    full_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "    \n",
    "    # Extract ONLY the assistant part\n",
    "    if \"<|im_start|>assistant<|im_sep|>\" in full_text:\n",
    "        assistant_part = full_text.split(\"<|im_start|>assistant<|im_sep|>\")[1]\n",
    "        assistant_part = assistant_part.split(\"<|im_end|>\")[0]\n",
    "    else:\n",
    "        assistant_part = full_text\n",
    "    \n",
    "    return assistant_part.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4f6ecf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# ===================================================================\n",
    "# ADD THIS FUNCTION AFTER YOUR generate_clinical_note FUNCTION\n",
    "# ===================================================================\n",
    "\n",
    "def convert_to_soap_format(clinical_note: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert model output to standard SOAP format\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"\"\"You are a medical documentation specialist. Convert the given clinical note into proper SOAP format.\n",
    "\n",
    "SOAP Format:\n",
    "\n",
    "SUBJECTIVE:\n",
    "- Chief Complaint\n",
    "- History of Present Illness\n",
    "- Past Medical History\n",
    "- Medications\n",
    "- Allergies\n",
    "- Family History\n",
    "- Social History\n",
    "\n",
    "OBJECTIVE:\n",
    "- Vital Signs (if available)\n",
    "- Physical Examination\n",
    "- Review of Systems\n",
    "- Labs/Imaging (if mentioned)\n",
    "\n",
    "ASSESSMENT:\n",
    "- Diagnoses (numbered list)\n",
    "\n",
    "PLAN:\n",
    "- Diagnostic workup\n",
    "- Medications\n",
    "- Procedures\n",
    "- Follow-up\n",
    "- Patient education\n",
    "- Referrals\n",
    "\n",
    "Use ONLY the information provided. Write \"Not documented\" for missing sections.\"\"\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Convert to SOAP format:\\n\\n{clinical_note}\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"SOAP conversion failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05195151",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# ===================================================================\n",
    "# CELL 6: Test Model (Optional)\n",
    "# ===================================================================\n",
    "# Quick test to verify model works\n",
    "test_dialogue = \"\"\"Doctor: Hello, how are you feeling today?\n",
    "Patient: I've been having headaches for the past week.\n",
    "Doctor: Can you describe the headaches?\n",
    "Patient: They're on the right side of my head, throbbing pain.\n",
    "Doctor: Any nausea or vision changes?\n",
    "Patient: Yes, some nausea but no vision problems.\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TESTING MODEL\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nTest Dialogue:\")\n",
    "print(test_dialogue)\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Generated Clinical Note:\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "test_note = generate_clinical_note(test_dialogue)\n",
    "print(test_note)\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b332cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# ===================================================================\n",
    "# UPDATE YOUR process_audio_to_clinical_note FUNCTION\n",
    "# ===================================================================\n",
    "\n",
    "def process_audio_to_clinical_note(audio_file_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Complete pipeline with SOAP formatting\n",
    "    \"\"\"\n",
    "    print(\"Step 1: Transcribing audio...\")\n",
    "    transcription = transcribe_audio(audio_file_path)\n",
    "    print(f\"✓ Transcription complete ({len(transcription)} characters)\")\n",
    "    \n",
    "    print(\"\\nStep 2: Segmenting dialogue...\")\n",
    "    segmented_dialogue = segment_dialogue(transcription)\n",
    "    print(\"✓ Dialogue segmentation complete\")\n",
    "    \n",
    "    print(\"\\nStep 3: Generating clinical note...\")\n",
    "    clinical_note = generate_clinical_note(segmented_dialogue)\n",
    "    print(\"✓ Clinical note generated\")\n",
    "    \n",
    "    print(\"\\nStep 4: Converting to SOAP format...\")\n",
    "    soap_note = convert_to_soap_format(clinical_note)\n",
    "    print(\"✓ SOAP format applied\")\n",
    "    \n",
    "    return {\n",
    "        \"transcription\": transcription,\n",
    "        \"segmented_dialogue\": segmented_dialogue,\n",
    "        \"clinical_note\": clinical_note,  # Original format\n",
    "        \"soap_note\": soap_note            # NEW: SOAP formatted\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bbd58b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# CELL 11: API Endpoints\n",
    "# ===================================================================\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return {\n",
    "        \"status\": \"running\",\n",
    "        \"message\": \"Clinical Note Generation API is operational\",\n",
    "        \"endpoints\": {\n",
    "            \"POST /upload-audio\": \"Upload audio file for complete processing\",\n",
    "            \"POST /transcribe\": \"Transcribe audio file\",\n",
    "            \"POST /segment\": \"Segment transcribed text into dialogue\",\n",
    "            \"POST /generate-note\": \"Generate clinical note from dialogue\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "@app.post(\"/upload-audio\", response_model=PipelineResponse)\n",
    "async def upload_audio(file: UploadFile = File(...)):\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.filename)[1]) as tmp_file:\n",
    "            content = await file.read()\n",
    "            tmp_file.write(content)\n",
    "            tmp_file_path = tmp_file.name\n",
    "        \n",
    "        result = process_audio_to_clinical_note(tmp_file_path)\n",
    "        os.unlink(tmp_file_path)\n",
    "        \n",
    "        return PipelineResponse(\n",
    "            transcription=result[\"transcription\"],\n",
    "            segmented_dialogue=result[\"segmented_dialogue\"],\n",
    "            clinical_note=result[\"clinical_note\"],\n",
    "            soap_note=result[\"soap_note\"],  # NEW\n",
    "            success=True,\n",
    "            message=\"Audio processed successfully\"\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.post(\"/transcribe\")\n",
    "async def transcribe_endpoint(file: UploadFile = File(...)):\n",
    "    \"\"\"\n",
    "    Transcribe audio file only\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.filename)[1]) as tmp_file:\n",
    "            content = await file.read()\n",
    "            tmp_file.write(content)\n",
    "            tmp_file_path = tmp_file.name\n",
    "        \n",
    "        transcription = transcribe_audio(tmp_file_path)\n",
    "        os.unlink(tmp_file_path)\n",
    "        \n",
    "        return {\n",
    "            \"transcription\": transcription,\n",
    "            \"success\": True\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.post(\"/segment\")\n",
    "async def segment_endpoint(request: TranscriptionRequest):\n",
    "    \"\"\"\n",
    "    Segment transcribed text into dialogue\n",
    "    \"\"\"\n",
    "    try:\n",
    "        segmented = segment_dialogue(request.text)\n",
    "        return {\n",
    "            \"segmented_dialogue\": segmented,\n",
    "            \"success\": True\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.post(\"/generate-note\")\n",
    "async def generate_note_endpoint(request: DialogueRequest):\n",
    "    \"\"\"\n",
    "    Generate clinical note from dialogue\n",
    "    \"\"\"\n",
    "    try:\n",
    "        note = generate_clinical_note(request.dialogue)\n",
    "        return {\n",
    "            \"clinical_note\": note,\n",
    "            \"success\": True\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2f7a7c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# ===================================================================\n",
    "# CELL 12: Start FastAPI Server with ngrok (BULLETPROOF COLAB VERSION)\n",
    "# ===================================================================\n",
    "import threading\n",
    "import uvicorn\n",
    "\n",
    "print(\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════╗\n",
    "║          FASTAPI SERVER + NGROK – PUBLIC API READY           ║\n",
    "╚══════════════════════════════════════════════════════════════╝\n",
    "\"\"\")\n",
    "\n",
    "# Your ngrok token\n",
    "ngrok.set_auth_token(\"enter ngrok key\")\n",
    "\n",
    "# Start ngrok tunnel first\n",
    "tunnel = ngrok.connect(8000)\n",
    "public_url = tunnel.public_url\n",
    "\n",
    "print(f\"✓ Public URL → {public_url}\\n\")\n",
    "print(\"=\"*70)\n",
    "print(\"API ENDPOINTS:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Health Check    : {public_url}/\")\n",
    "print(f\"Full Pipeline   : {public_url}/upload-audio\")\n",
    "print(f\"Swagger UI/Docs : {public_url}/docs\")   # ← Open this and test instantly\n",
    "print(f\"Redoc           : {public_url}/redoc\")\n",
    "print(\"=\"*70)\n",
    "print(\"Server is now running permanently in background thread!\")\n",
    "print(\"You can close this cell — the API stays alive until runtime disconnects.\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Run uvicorn in a background thread → completely bypasses the asyncio error\n",
    "def run_uvicorn():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "\n",
    "thread = threading.Thread(target=run_uvicorn, daemon=True)\n",
    "thread.start()\n",
    "\n",
    "# Optional: keep the cell \"running\" visually so Colab doesn't show \"finished\"\n",
    "import time\n",
    "while True:\n",
    "    time.sleep(60)\n",
    "    print(f\"Server still alive @ {public_url}/docs\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
